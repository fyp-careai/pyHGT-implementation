{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxfJ7CRE3NMn",
        "outputId": "e7e22e0f-36b6-4688-9808-928015c1f33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.12/dist-packages (from torchdata) (2.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchdata) (2.32.4)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.12/dist-packages (from torchdata) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->torchdata) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchdata) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2->torchdata) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2->torchdata) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ],
      "metadata": {
        "id": "UAhP7nYTtHzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f21618-bfef-418f-b5b9-c0d754f7a825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwO37rnUh3p1",
        "outputId": "97b93c6a-33ba-4e0f-8684-a81a3295cfcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_aggregate_visits(visit_features, output_dim):\n",
        "    \"\"\"\n",
        "    Implements the Simple Aggregation (Baseline 1) method (Mean/Flattening).\n",
        "    Averages all features across the time dimension.\n",
        "    visit_features shape: (sequence_length, input_dim)\n",
        "    \"\"\"\n",
        "    if visit_features.size(0) == 0:\n",
        "        return torch.zeros(output_dim)\n",
        "\n",
        "    # 1. Take the mean across the time dimension (axis 0)\n",
        "    mean_features = torch.mean(visit_features, dim=0)\n",
        "\n",
        "    # 2. Project to the target output_dim (Requires a trained linear layer)\n",
        "    # --- DUMMY PROJECTION ---\n",
        "    # In a real setup, this linear layer (L1) would be trained with the GNN.\n",
        "    DUMMY_PROJ_LAYER = nn.Linear(mean_features.size(-1), output_dim)\n",
        "    return F.relu(DUMMY_PROJ_LAYER(mean_features))\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom module to remove the right-side padding artifacts from Conv1d output.\n",
        "    This replaces the problematic lambda function.\n",
        "    \"\"\"\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, channels, seq_len)\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    \"\"\"A basic residual block for TCNs.\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, dropout):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        padding = (kernel_size - 1) * dilation\n",
        "\n",
        "        # 1D Convolution for time series data\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding) # Remove padding artifacts\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "\n",
        "        # Residual connection: projects input dimension if necessary\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(self.net(x) + res)\n",
        "\n",
        "\n",
        "class TCNEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encodes a sequence of patient visits using TCN (Method 3).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_channels, output_dim, num_layers, kernel_size, dropout):\n",
        "        super(TCNEncoder, self).__init__()\n",
        "\n",
        "        # TCN layers\n",
        "        layers = []\n",
        "        in_channels = input_dim\n",
        "        for i in range(num_layers):\n",
        "            # Dilated convolutions to capture wider context\n",
        "            dilation_size = 2 ** i\n",
        "            out_channels = hidden_channels\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size, dropout=dropout)]\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.tcn = nn.Sequential(*layers)\n",
        "\n",
        "        # Final projection layer to match the required h_patient^0 size\n",
        "        self.fc = nn.Linear(hidden_channels, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, visit_sequences):\n",
        "        # TCN expects shape: (batch_size, channels, sequence_length)\n",
        "        # Input sequence is (batch_size, sequence_length, input_dim)\n",
        "        x = visit_sequences.transpose(1, 2)\n",
        "\n",
        "        # TCN output shape: (batch_size, channels, new_sequence_length)\n",
        "        output = self.tcn(x)\n",
        "\n",
        "        # For a prediction, we use the features of the last \"time step\"\n",
        "        # The last time step is the last column in the output tensor\n",
        "        h_T = output[:, :, -1]\n",
        "\n",
        "        # Final projection\n",
        "        z = self.relu(self.fc(h_T))\n",
        "        return z\n",
        "# ==============================================================================\n",
        "# COMMON DATA TRANSFORMATION UTILITY\n",
        "# ==============================================================================\n",
        "\n",
        "def transform_raw_to_features(group: pd.DataFrame, concept_map: dict, value_dim: int):\n",
        "    \"\"\"\n",
        "    Converts a patient's raw records into a sequence of feature vectors (visits).\n",
        "    This function implements Step 1.2's concept: map TestName/Value to a fixed-size vector.\n",
        "\n",
        "    Args:\n",
        "        group: All records for a single patient, sorted by time.\n",
        "        concept_map: Map of all unique TestNames to an index.\n",
        "        value_dim: The feature dimension to be used for continuous values (e.g., 1 for normalized value).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A sequence of feature vectors (sequence_length, total_input_dim)\n",
        "    \"\"\"\n",
        "    # Group records by ReportDate (A single 'visit' is all tests taken at the exact same time)\n",
        "    visits = group.groupby('ReportDate').agg(list)\n",
        "\n",
        "    num_concepts = len(concept_map)\n",
        "    feature_list = []\n",
        "\n",
        "    for _, visit in visits.iterrows():\n",
        "        # Initialize a feature vector for this visit (num_concepts * value_dim)\n",
        "        # Using value_dim=1 (normalized value) and assuming a dense matrix where\n",
        "        # all possible concepts are represented.\n",
        "        visit_vector = torch.zeros(num_concepts * value_dim)\n",
        "\n",
        "        test_names = visit['TestName']\n",
        "        test_values = visit['TestValue']\n",
        "\n",
        "        for name, value in zip(test_names, test_values):\n",
        "            if name in concept_map:\n",
        "                idx = concept_map[name]\n",
        "                # DUMMY: Apply a simple normalization for the value\n",
        "                normalized_value = float(value) / 100.0 # Placeholder normalization\n",
        "\n",
        "                # Insert the normalized value into the vector at the concept's index\n",
        "                visit_vector[idx] = normalized_value\n",
        "\n",
        "        feature_list.append(visit_vector)\n",
        "\n",
        "    if not feature_list:\n",
        "        return torch.empty(0, num_concepts * value_dim)\n",
        "\n",
        "    return torch.stack(feature_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "x5t-U5mStqI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import HeteroData\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict\n",
        "\n",
        "print(torch.__version__)\n",
        "def construct_patient_symptom_bipartite_graph(\n",
        "    patient_ids: list,\n",
        "    patient_features: Dict[int, torch.Tensor],\n",
        "    patient_idx_map: dict,\n",
        "    concept_map: dict,\n",
        "    raw_data: pd.DataFrame\n",
        ") -> HeteroData:\n",
        "    \"\"\"\n",
        "    Constructs the Patient <-> Symptom Bipartite Graph (P Graph core) using\n",
        "    pre-computed patient embeddings.\n",
        "\n",
        "    Args:\n",
        "        patient_ids: List of all valid patient IDs.\n",
        "        patient_features: Dictionary of {PatientID: h_patient^0 tensor}.\n",
        "        patient_idx_map: Map from PatientID to node index (0 to N-1).\n",
        "        concept_map: Map from TestName (Symptom) to node index (0 to M-1).\n",
        "        raw_data: DataFrame of patient EMR records.\n",
        "\n",
        "    Returns:\n",
        "        HeteroData: Graph containing Patient and Symptom nodes, and P->S edges.\n",
        "    \"\"\"\n",
        "    data = HeteroData()\n",
        "\n",
        "    # --- Node Initialization ---\n",
        "    num_patients = len(patient_ids)\n",
        "    num_symptoms = len(concept_map)\n",
        "\n",
        "    # Check for valid features\n",
        "    if not patient_ids:\n",
        "        print(\"[ERROR] No valid patients found. Cannot build graph.\")\n",
        "        return data\n",
        "\n",
        "    gnn_embedding_dim = patient_features[patient_ids[0]].shape[0]\n",
        "\n",
        "    # 1. Patient Node Features (h_patient^0)\n",
        "    data['patient'].x = torch.stack([patient_features[id] for id in patient_ids])\n",
        "    data['patient'].node_map = patient_idx_map\n",
        "\n",
        "    # 2. Symptom Node Features (random initialization for shared embedding space)\n",
        "    data['symptom'].x = torch.rand(num_symptoms, gnn_embedding_dim)\n",
        "    data['symptom'].node_map = concept_map\n",
        "\n",
        "    # --- Edge Construction (Patient -> Symptom) ---\n",
        "    p_to_s_edges = []\n",
        "\n",
        "    filtered_df = raw_data[raw_data['PatientID'].isin(patient_features.keys())]\n",
        "\n",
        "    # Iterate over raw records to build connections\n",
        "    for _, row in raw_data.iterrows():\n",
        "        p_id = row['PatientID']\n",
        "        s_name = row['TestName']\n",
        "\n",
        "        # Ensure ID/Name exists in our processed maps\n",
        "        if p_id in patient_idx_map and s_name in concept_map:\n",
        "            p_idx = patient_idx_map[p_id]\n",
        "            s_idx = concept_map[s_name]\n",
        "            p_to_s_edges.append((p_idx, s_idx))\n",
        "\n",
        "    if p_to_s_edges:\n",
        "        src, dst = zip(*p_to_s_edges)\n",
        "        # Edge indices are stored as (2, num_edges) tensor\n",
        "        data['patient', 'has', 'symptom'].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
        "        data['symptom', 'is_related_to', 'patient'].edge_index = torch.tensor([dst, src], dtype=torch.long)\n",
        "        print(f\"[SUCCESS] Built {len(p_to_s_edges)} P->S edges.\")\n",
        "    else:\n",
        "        data['patient', 'has', 'symptom'].edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        data['symptom', 'is_related_to', 'patient'].edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        print(\"[WARN] No P->S edges created.\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def construct_symptom_organ_graph(\n",
        "    concept_map: dict,\n",
        "    organ_map: dict,\n",
        "    raw_data: pd.DataFrame\n",
        ") -> HeteroData:\n",
        "    \"\"\"Creates the Symptom -> Organ bipartite graph.\"\"\"\n",
        "    data = HeteroData()\n",
        "\n",
        "    # Placeholder node initialization (features will be added during final integration)\n",
        "    data['symptom'].num_nodes = len(concept_map)\n",
        "    data['organ'].num_nodes = len(organ_map)\n",
        "\n",
        "    s_to_o_edges = []\n",
        "    for _,row in raw_data.iterrows():\n",
        "        s_name = row['TestName']\n",
        "        o_name = row['Target_Organ']\n",
        "        if s_name in concept_map and o_name in organ_map:\n",
        "            s_idx = concept_map[s_name]\n",
        "            o_idx = organ_map[o_name]\n",
        "            s_to_o_edges.append((s_idx, o_idx))\n",
        "\n",
        "    if s_to_o_edges:\n",
        "        src, dst = zip(*s_to_o_edges)\n",
        "        data['symptom', 'measures', 'organ'].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
        "        print(f\"[SUCCESS] Symptom -> Organ Graph built with {len(s_to_o_edges)} edges.\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def construct_disease_organ_graph(\n",
        "    disease_map: dict,\n",
        "    organ_map: dict,\n",
        "    raw_data: pd.DataFrame\n",
        ") -> HeteroData:\n",
        "    \"\"\"Creates the disease -> Organ bipartite graph.\"\"\"\n",
        "    data = HeteroData()\n",
        "\n",
        "    # Placeholder node initialization (features will be added during final integration)\n",
        "    data['disease'].num_nodes = len(disease_map)\n",
        "    data['organ'].num_nodes = len(organ_map)\n",
        "\n",
        "    o_to_d_edges = []\n",
        "    for _,row in raw_data.iterrows():\n",
        "        d_name = row['Most_Relevant_Disease']\n",
        "        o_name = row['Target_Organ']\n",
        "        if d_name in disease_map and o_name in organ_map:\n",
        "            s_idx = disease_map[d_name]\n",
        "            o_idx = organ_map[o_name]\n",
        "            o_to_d_edges.append((o_idx, s_idx))\n",
        "\n",
        "    if o_to_d_edges:\n",
        "        src, dst = zip(*o_to_d_edges)\n",
        "        data['organ', 'is affected', 'disease'].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
        "        print(f\"[SUCCESS] Disease -> Organ Graph built with {len(o_to_d_edges)} edges.\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CORE FUNCTION: Disease & Organ Graph Builder (The requested logic)\n",
        "# ==============================================================================\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "class PatientData:\n",
        "    \"\"\"A container for pre-processed features and maps.\"\"\"\n",
        "    def __init__(self, patient_features_dict,final_patient_ids, final_patient_idx_map , concept_map, disease_map, organ_map,ext_ps, ext_so, ext_do,patient_labels):\n",
        "        self.patient_features = patient_features_dict\n",
        "        self.final_patient_ids = final_patient_ids\n",
        "        self.final_patient_idx_map = final_patient_idx_map\n",
        "        self.concept_map = concept_map\n",
        "        self.disease_map = disease_map\n",
        "        self.organ_map = organ_map\n",
        "        self.patient_symptom_edges = ext_ps\n",
        "        self.symptom_organ_edges = ext_so\n",
        "        self.organ_disease_edges = ext_do\n",
        "        #self.raw_data = raw_data\n",
        "        self.patient_labels = patient_labels\n",
        "\n",
        "        self.X_patients = torch.stack([self.patient_features[id] for id in self.final_patient_ids])\n",
        "        self.gnn_embedding_dim = self.X_patients.shape[1]\n",
        "        self.num_diseases = len(disease_map)\n",
        "        self.num_symptoms = len(concept_map)\n",
        "        self.num_organs = len(organ_map)\n",
        "        self.num_patient_ids = len(final_patient_ids)\n",
        "\n",
        "\n",
        "def construct_final_unified_graph(\n",
        "    ps_graph: HeteroData,\n",
        "    so_graph: HeteroData,\n",
        "    od_graph: HeteroData,\n",
        "    data_obj: PatientData\n",
        ") -> HeteroData:\n",
        "    \"\"\"\n",
        "    Merges all four bipartite graphs (P-S, S-O, D-O, D-S) into a single\n",
        "    HeteroData object and finalizes node features and labels.\n",
        "    \"\"\"\n",
        "    final_data = HeteroData()\n",
        "    emb_dim = data_obj.gnn_embedding_dim\n",
        "\n",
        "    # --- 2.1. Node Initialization and Feature Transfer (Merging P, S, D, O) ---\n",
        "\n",
        "    # P Nodes (Features from TCN/Aggregate)\n",
        "    final_data['patient'].x = ps_graph['patient'].x\n",
        "\n",
        "    # S Nodes (Shared: Features initialized in P-S graph)\n",
        "    final_data['symptom'].x = ps_graph['symptom'].x\n",
        "\n",
        "    # D Nodes (Initialized randomly)\n",
        "    final_data['disease'].x = torch.rand(data_obj.num_diseases, emb_dim)\n",
        "\n",
        "    # O Nodes (Initialized randomly)\n",
        "    final_data['organ'].x = torch.rand(data_obj.num_organs, emb_dim)\n",
        "\n",
        "    # --- 2.2. Edge Transfer (Merging Graph Components) ---\n",
        "\n",
        "    # 1. P -> S (EMR Data)\n",
        "    final_data['patient', 'has', 'symptom'].edge_index = ps_graph['patient', 'has', 'symptom'].edge_index\n",
        "    final_data['symptom', 'is_related_to', 'patient'].edge_index = ps_graph['symptom', 'is_related_to', 'patient'].edge_index\n",
        "\n",
        "    # 2. S -> O (Knowledge: Symptom measures Organ)\n",
        "    final_data['symptom', 'measures', 'organ'].edge_index = so_graph['symptom', 'measures', 'organ'].edge_index\n",
        "\n",
        "    # 3. D -> O (Knowledge: Disease affects Organ)\n",
        "    final_data['organ', 'is affected', 'disease'].edge_index = od_graph['organ', 'is affected', 'disease'].edge_index\n",
        "\n",
        "    # 4. D -> S (Knowledge: Disease is linked to Symptom)\n",
        "    #final_data['disease', 'linked_to', 'symptom'].edge_index = ds_graph['disease', 'linked_to', 'symptom'].edge_index\n",
        "\n",
        "    # --- 2.3. Final Labels and Metadata ---\n",
        "    final_data['patient'].y = torch.stack([data_obj.patient_labels[id] for id in data_obj.final_patient_ids])\n",
        "    final_data['disease'].y_identity = torch.eye(data_obj.num_diseases)\n",
        "\n",
        "    # --- 2.4. Debugging and Verification ---\n",
        "\n",
        "    print(\"\\n--- DEBUG: Graph Integration Verification ---\")\n",
        "\n",
        "    # D.1. Check Node Counts\n",
        "    nodes_check = [\n",
        "        ('patient', data_obj.patient_features), ('symptom', data_obj.concept_map),\n",
        "        ('disease', data_obj.disease_map), ('organ', data_obj.organ_map)\n",
        "    ]\n",
        "    for name, source in nodes_check:\n",
        "        expected = len(source)\n",
        "        actual = final_data[name].x.shape[0]\n",
        "        status = \"[OK]\" if actual == expected else f\"[FAIL] Expected {expected}\"\n",
        "        print(f\"  Node Type {name.upper()}: {actual} {status}\")\n",
        "\n",
        "    # D.2. Check Edge Counts\n",
        "    edges_check = [\n",
        "        (('patient', 'has', 'symptom'), len(data_obj.patient_symptom_edges)),\n",
        "        (('symptom', 'is_related_to', 'patient'), len(data_obj.patient_symptom_edges)),\n",
        "        (('symptom', 'measures', 'organ'), len(data_obj.symptom_organ_edges)),\n",
        "        (('organ', 'is affected', 'disease'), len(data_obj.organ_disease_edges)),\n",
        "        #(('disease', 'linked_to', 'symptom'), len(data_obj.external_knowledge_ds))\n",
        "    ]\n",
        "    total_edges = 0\n",
        "    for edge_type, expected_count in edges_check:\n",
        "        actual_count = final_data[edge_type].edge_index.shape[1]\n",
        "        total_edges += actual_count\n",
        "        status = \"[OK]\" if actual_count == expected_count else f\"[FAIL] Expected {expected_count}\"\n",
        "        print(f\"  Edge Type {edge_type[1].upper()}: {actual_count} {status}\")\n",
        "\n",
        "    print(f\"  TOTAL Edges Unified: {total_edges}\")\n",
        "    print(\"---------------------------------------\")\n",
        "\n",
        "    return final_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMO-Y0TNyF52",
        "outputId": "72d7e212-ab15-49ff-8dba-1749116f91c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gen-0",
        "outputId": "22450b06-5d94-46c1-dd77-f5d65193cc52"
      },
      "source": [
        "!pip install torch_geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def identify_patient_symptom_relations(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Identifies and counts the frequency of the Patient <-> Symptom relationship\n",
        "    in the raw EMR data. This forms the base of the Patient Record Graph (P).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Strip column names again for safety\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # 2. Extract unique Patient and Symptom IDs\n",
        "    unique_patients = df['PatientID'].unique()\n",
        "    unique_symptoms = df['TestName'].unique()\n",
        "\n",
        "    print(\"\\n--- Relationship Identification ---\")\n",
        "    print(f\"Total Unique Patients (Nodes): {len(unique_patients)}\")\n",
        "    print(f\"Total Unique Symptoms (Nodes): {len(unique_symptoms)}\")\n",
        "\n",
        "    # 3. Aggregate the number of times each unique P->S edge appears (for weighting later)\n",
        "    # This result is the adjacency list/matrix entries for the P Graph.\n",
        "    relation_counts = df.groupby(['PatientID', 'TestName']).size().reset_index(name='Frequency')\n",
        "\n",
        "    print(\"\\n[Relationship 1: Patient <-> Symptom (P Graph)]\")\n",
        "    print(f\"Total unique Patient-Symptom links (edges): {len(relation_counts)}\")\n",
        "    print(\"Example Links and Frequencies:\")\n",
        "    print(relation_counts.head())\n",
        "\n",
        "    # Check for patients with high connectivity (potential hubs)\n",
        "    patient_connectivity = relation_counts.groupby('PatientID')['Frequency'].sum().nlargest(3)\n",
        "    #print(f\"\\nTop 3 Patients by total symptom records (Hubs): \\n{patient_connectivity}\")\n",
        "\n",
        "    return relation_counts\n",
        "\n",
        "\n",
        "def analyze_symptom_connectivity(raw_relation_counts: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Calculates the number of unique patient relations for each symptom.\n",
        "    This helps identify rare vs. common symptoms.\n",
        "    \"\"\"\n",
        "\n",
        "    # The 'raw_relation_counts' table already holds UNIQUE (PatientID, TestName) pairs,\n",
        "    # so we just need to count how many unique patients each TestName is linked to.\n",
        "\n",
        "    # The 'Frequency' column holds the count of how many TIMES that specific P->S pair appeared.\n",
        "    # To get unique patient connectivity (the degree of the symptom node):\n",
        "\n",
        "    # 1. Group by TestName and count the number of unique PatientIDs connected to it.\n",
        "    symptom_connectivity = raw_relation_counts.groupby('TestName')['PatientID'].nunique().reset_index(name='Unique_Patient_Count')\n",
        "\n",
        "    print(\"\\n--- Symptom Node Connectivity Analysis ---\")\n",
        "\n",
        "    # 2. Identify the most and least connected symptoms\n",
        "    most_common = symptom_connectivity.sort_values(by='Unique_Patient_Count', ascending=False).head(5)\n",
        "    least_common = symptom_connectivity.sort_values(by='Unique_Patient_Count', ascending=True).head(5)\n",
        "\n",
        "    print(\"\\nTop 5 Most Connected Symptoms (Common/Hub Symptoms):\")\n",
        "    print(most_common)\n",
        "\n",
        "    print(\"\\nTop 5 Least Connected Symptoms (Potential Rare/Specific Symptoms):\")\n",
        "    print(least_common)\n",
        "\n",
        "    return symptom_connectivity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def identify_organ_symptom_relations(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Identifies and counts the frequency of the Patient <-> Symptom relationship\n",
        "    in the raw EMR data. This forms the base of the Patient Record Graph (P).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Strip column names again for safety\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # 2. Extract unique Patient and Symptom IDs\n",
        "    unique_organ = df['Target_Organ'].unique()\n",
        "    unique_symptoms = df['TestName'].unique()\n",
        "\n",
        "    print(\"\\n--- Relationship Identification ---\")\n",
        "    print(f\"Total Unique Organs (Nodes): {len(unique_organ)}\")\n",
        "    print(f\"Total Unique Symptoms (Nodes): {len(unique_symptoms)}\")\n",
        "\n",
        "    # 3. Aggregate the number of times each unique P->S edge appears (for weighting later)\n",
        "    # This result is the adjacency list/matrix entries for the P Graph.\n",
        "    relation_counts = df.groupby(['Target_Organ', 'TestName']).size().reset_index(name='Frequency')\n",
        "\n",
        "    print(\"\\n[Relationship 1: Organ <-> Symptom (SO Graph)]\")\n",
        "    print(f\"Total unique Organ-Symptom links (edges): {len(relation_counts)}\")\n",
        "    print(\"Example Links and Frequencies:\")\n",
        "    print(relation_counts.head())\n",
        "\n",
        "    # Check for patients with high connectivity (potential hubs)\n",
        "    patient_connectivity = relation_counts.groupby('Target_Organ')['Frequency'].sum().nlargest(3)\n",
        "    #print(f\"\\nTop 3 Patients by total symptom records (Hubs): \\n{patient_connectivity}\")\n",
        "\n",
        "    return relation_counts\n",
        "\n",
        "\n",
        "\n",
        "def identify_organ_disease_relations(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Identifies and counts the frequency of the Patient <-> Symptom relationship\n",
        "    in the raw EMR data. This forms the base of the Patient Record Graph (P).\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Strip column names again for safety\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # 2. Extract unique Patient and Symptom IDs\n",
        "    unique_organ = df['Target_Organ'].unique()\n",
        "    unique_disease = df['Most_Relevant_Disease'].unique()\n",
        "\n",
        "    print(\"\\n--- Relationship Identification ---\")\n",
        "    print(f\"Total Unique Organs (Nodes): {len(unique_organ)}\")\n",
        "    print(f\"Total Unique diseases (Nodes): {len(unique_disease)}\")\n",
        "\n",
        "    # 3. Aggregate the number of times each unique P->S edge appears (for weighting later)\n",
        "    # This result is the adjacency list/matrix entries for the P Graph.\n",
        "    relation_counts = df.groupby(['Target_Organ', 'Most_Relevant_Disease']).size().reset_index(name='Frequency')\n",
        "\n",
        "    print(\"\\n[Relationship 1: Organ <-> Disease (OD Graph)]\")\n",
        "    print(f\"Total unique Organ-Disease links (edges): {len(relation_counts)}\")\n",
        "    print(\"Example Links and Frequencies:\")\n",
        "    print(relation_counts.head())\n",
        "\n",
        "    # Check for patients with high connectivity (potential hubs)\n",
        "    patient_connectivity = relation_counts.groupby('Target_Organ')['Frequency'].sum().nlargest(3)\n",
        "    print(f\"\\nTop 3 Patients by total symptom records (Hubs): \\n{patient_connectivity}\")\n",
        "\n",
        "    return relation_counts"
      ],
      "metadata": {
        "id": "18S-U30nA82j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GATConv, HeteroConv\n",
        "\n",
        "from torch_geometric.nn import HANConv\n",
        "\n",
        "def extract_metapaths(metadata):\n",
        "    node_types, edge_types = metadata\n",
        "    metapaths = []\n",
        "    for src1, rel1, dst1 in edge_types:\n",
        "        for src2, rel2, dst2 in edge_types:\n",
        "            if dst1 == src2:  # chain\n",
        "                metapaths.append([(src1, rel1, dst1), (src2, rel2, dst2)])\n",
        "    return metapaths\n",
        "\n",
        "\n",
        "class GNNEncoderHAN(nn.Module):\n",
        "    def __init__(self, metadata, metapaths, hidden_channels, out_channels, num_heads=4):\n",
        "        super(GNNEncoderHAN, self).__init__()\n",
        "        self.metapaths = metapaths\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "\n",
        "        # HAN handles all hetero types internally using metapaths\n",
        "        self.han_conv = HANConv(\n",
        "            in_channels={nt: -1 for nt in metadata[0]},\n",
        "            out_channels=hidden_channels,\n",
        "            metadata=metadata,\n",
        "            heads=num_heads,\n",
        "        )\n",
        "\n",
        "        self.han_conv2 = HANConv(\n",
        "        in_channels={nt: hidden_channels for nt in metadata[0]},\n",
        "        out_channels=hidden_channels,\n",
        "        metadata=metadata,\n",
        "        heads=num_heads\n",
        "        )\n",
        "\n",
        "        self.proj = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        # HANConv automatically uses metapaths, ignores raw edge_index_dict\n",
        "        x_dict = self.han_conv(x_dict, edge_index_dict)\n",
        "        x_dict = {k: self.dropout(F.relu(v)) for k, v in x_dict.items()}\n",
        "        x_dict = self.han_conv2(x_dict, edge_index_dict)\n",
        "        x_dict = {k: self.dropout(F.relu(v)) for k, v in x_dict.items()}\n",
        "\n",
        "        # Project to final embedding dim\n",
        "        z_dict = {}\n",
        "        for node_type, x in x_dict.items():\n",
        "            z_dict[node_type] = F.relu(self.proj(x))\n",
        "\n",
        "        return z_dict\n",
        "\n",
        "\n",
        "\n",
        "class GNNEncoderHGAT(nn.Module):\n",
        "    # (HGAT Encoder code provided in the prompt)\n",
        "    def __init__(self, metadata, hidden_channels: int, out_channels: int, num_layers: int = 2, num_heads: int = 4):\n",
        "        super(GNNEncoderHGAT, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            conv = HeteroConv({\n",
        "                edge_type: GATConv(in_channels=(-1, -1), out_channels=hidden_channels // num_heads, heads=num_heads, add_self_loops=False)\n",
        "                for edge_type in metadata[1]\n",
        "            }, aggr='sum')\n",
        "            self.convs.append(conv)\n",
        "        self.proj = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x_dict: Dict[str, torch.Tensor], edge_index_dict: Dict[Tuple, torch.Tensor]):\n",
        "        for i in range(self.num_layers):\n",
        "            x_dict = self.convs[i](x_dict, edge_index_dict)\n",
        "            x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
        "        z_dict = {}\n",
        "        for node_type, x in x_dict.items():\n",
        "            z_dict[node_type] = F.relu(self.proj(x))\n",
        "        return z_dict\n",
        "\n",
        "class GraphDecoder(nn.Module):\n",
        "    def __init__(self, embedding_dim: int, num_diseases: int):\n",
        "        super(GraphDecoder, self).__init__()\n",
        "        self.Q = nn.Parameter(torch.rand(embedding_dim, num_diseases))\n",
        "        self.G = nn.Parameter(torch.rand(embedding_dim, num_diseases))\n",
        "    def forward(self, z_dict: Dict[str, torch.Tensor]):\n",
        "        z_p = z_dict['patient']\n",
        "        z_m = z_dict['disease']\n",
        "        c_p_hat = torch.sigmoid(z_p @ self.Q)\n",
        "        c_m_hat = torch.sigmoid(z_m @ self.G)\n",
        "        return c_p_hat, c_m_hat\n",
        "\n",
        "class DiseasePredictionModelHGAT(nn.Module):\n",
        "    def __init__(self, data_metadata, embedding_dim: int, num_diseases: int):\n",
        "        super(DiseasePredictionModelHGAT, self).__init__()\n",
        "        hidden_channels = embedding_dim # Simple mapping\n",
        "        self.encoder = GNNEncoderHGAT(data_metadata, hidden_channels=hidden_channels, out_channels=embedding_dim, num_layers=2)\n",
        "        self.decoder = GraphDecoder(embedding_dim, num_diseases)\n",
        "\n",
        "    def forward(self, x_dict: Dict[str, torch.Tensor], edge_index_dict: Dict[Tuple, torch.Tensor]):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        c_p_hat, c_m_hat = self.decoder(z_dict)\n",
        "        return c_p_hat, c_m_hat\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='sum'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        inputs = torch.clamp(inputs, min=1e-9, max=1.0 - 1e-9)  # stability\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.where(targets == 1, inputs, 1 - inputs)\n",
        "        loss = self.alpha * (1 - pt) ** self.gamma * BCE\n",
        "        if self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        elif self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        return loss\n",
        "\n",
        "\n",
        "class DiseasePredictionModelHAN(nn.Module):\n",
        "    def __init__(self, metadata, metapaths, embedding_dim, num_diseases:int):\n",
        "        super(DiseasePredictionModelHAN, self).__init__()\n",
        "        hidden_channels = embedding_dim\n",
        "\n",
        "        self.encoder = GNNEncoderHAN(\n",
        "            metadata=metadata,\n",
        "            metapaths=metapaths,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=embedding_dim,\n",
        "            num_heads=4\n",
        "        )\n",
        "\n",
        "        self.decoder = GraphDecoder(embedding_dim, num_diseases)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        c_p_hat, c_m_hat = self.decoder(z_dict)\n",
        "        return c_p_hat, c_m_hat\n",
        "\n",
        "\n",
        "def negative_log_likelihood_loss(c_hat, c):\n",
        "    c_hat = torch.clamp(c_hat, min=1e-9, max=1.0 - 1e-9)\n",
        "    return F.binary_cross_entropy(c_hat, c, reduction='sum')\n",
        "\n",
        "def train_hgat_model(model: DiseasePredictionModelHGAT, full_graph: HeteroData, epochs=50, lr=0.001):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    c_p = full_graph['patient'].y\n",
        "    c_m = full_graph['disease'].y_identity\n",
        "    num_train = int(c_p.shape[0] * 0.8)\n",
        "    train_idx = torch.arange(num_train)\n",
        "\n",
        "    print(f\"\\nStarting HGAT Training with {num_train} samples...\")\n",
        "    focal_loss_fn = FocalLoss(alpha=1, gamma=2, reduction='sum')\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        c_p_hat, c_m_hat = model(full_graph.x_dict, full_graph.edge_index_dict)\n",
        "        L_P = focal_loss_fn(c_p_hat[train_idx], c_p[train_idx])\n",
        "        L_M = focal_loss_fn(c_m_hat, c_m)\n",
        "        loss = L_P + L_M\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
        "# The value 5.0 is a common starting point.\n",
        "        optimizer.step()\n",
        "\n",
        "        #if epoch % 10 == 0 or epoch == 1:\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss.item():.4f}, L_P: {L_P.item():.4f}, L_M: {L_M.item():.4f}')\n",
        "    print(\"\\nHGAT Model Training Complete. Ready for prediction.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def train(model, data, epochs=30, lr=1e-3, device=\"cpu\"):\n",
        "    model = model.to(device)\n",
        "\n",
        "    # 1. Move all features to device\n",
        "    feature_dict = {k: v.to(device) for k, v in data['features'].items()}\n",
        "    meta_neighbors = data['meta_neighbors']  # neighbors are index lists, no device needed\n",
        "\n",
        "    labels = data['labels'].to(device)\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        logits, Z_final, beta = model(feature_dict, meta_neighbors)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Loss = {loss.item():.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_hgan_model(model: DiseasePredictionModelHAN, full_graph: HeteroData, epochs=50, lr=0.001):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
        "    c_p = full_graph['patient'].y\n",
        "    c_m = full_graph['disease'].y_identity\n",
        "    num_train = int(c_p.shape[0] * 0.8)\n",
        "    train_idx = torch.arange(num_train)\n",
        "\n",
        "    print(f\"\\nStarting HGAT Training with {num_train} samples...\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        c_p_hat, c_m_hat = model(full_graph.x_dict, full_graph.edge_index_dict)\n",
        "        L_P = negative_log_likelihood_loss(c_p_hat[train_idx], c_p[train_idx])\n",
        "        L_M = negative_log_likelihood_loss(c_m_hat, c_m)\n",
        "        loss = L_P + L_M\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "# The value 5.0 is a common starting point.\n",
        "        optimizer.step()\n",
        "\n",
        "        #if epoch % 10 == 0 or epoch == 1:\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss.item():.4f}, L_P: {L_P.item():.4f}, L_M: {L_M.item():.4f}')\n",
        "    print(\"\\nHAN Model Training Complete. Ready for prediction.\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "QAu50uZNWfbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    f1_score, roc_auc_score, average_precision_score,\n",
        "    hamming_loss, coverage_error, label_ranking_loss\n",
        ")\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def evaluate_model(model, full_graph, k_list=[1,3,5]):\n",
        "    print(\"\\n========== MODEL EVALUATION ==========\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        c_p_hat, c_m_hat = model(full_graph.x_dict, full_graph.edge_index_dict)\n",
        "\n",
        "    # TRUE LABELS\n",
        "    y_true = full_graph['patient'].y.cpu()\n",
        "    y_pred = c_p_hat.cpu()\n",
        "\n",
        "    # Binarize using threshold 0.5\n",
        "    y_bin = (y_pred >= 0.5).int()\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    # 1. Micro & Macro F1\n",
        "    metrics['micro_f1'] = f1_score(y_true, y_bin, average='micro', zero_division=0)\n",
        "    metrics['macro_f1'] = f1_score(y_true, y_bin, average='macro', zero_division=0)\n",
        "\n",
        "    # 2. AUPRC (micro)\n",
        "    metrics['micro_auprc'] = average_precision_score(y_true, y_pred, average='micro')\n",
        "\n",
        "    # 3. ROC-AUC\n",
        "    try:\n",
        "        metrics['micro_auc'] = roc_auc_score(y_true, y_pred, average='micro')\n",
        "        metrics['macro_auc'] = roc_auc_score(y_true, y_pred, average='macro')\n",
        "    except:\n",
        "        metrics['micro_auc'] = None\n",
        "        metrics['macro_auc'] = None\n",
        "\n",
        "    # 4. Hamming Loss\n",
        "    metrics['hamming_loss'] = hamming_loss(y_true, y_bin)\n",
        "\n",
        "    # 5. Ranking Loss\n",
        "    metrics['ranking_loss'] = label_ranking_loss(y_true, y_pred)\n",
        "\n",
        "    # 6. Coverage Error\n",
        "    metrics['coverage_error'] = coverage_error(y_true, y_pred)\n",
        "\n",
        "    # 7. Top-k Accuracy\n",
        "    topk_results = {}\n",
        "    for k in k_list:\n",
        "        topk_pred = torch.topk(y_pred, k=k, dim=1).indices\n",
        "        correct = 0\n",
        "        for i in range(y_true.shape[0]):\n",
        "            true_labels = set(torch.where(y_true[i] == 1)[0].tolist())\n",
        "            predicted_labels = set(topk_pred[i].tolist())\n",
        "            if len(true_labels & predicted_labels) > 0:\n",
        "                correct += 1\n",
        "        topk_results[f\"top_{k}_accuracy\"] = correct / len(y_true)\n",
        "    metrics.update(topk_results)\n",
        "\n",
        "    # -------------------------\n",
        "    # DISEASE EMBEDDING METRICS\n",
        "    # -------------------------\n",
        "    y_d_true = full_graph['disease'].y_identity.cpu().float()\n",
        "    y_d_pred = c_m_hat.cpu().float()\n",
        "\n",
        "    metrics[\"disease_mse\"] = F.mse_loss(y_d_pred, y_d_true).item()\n",
        "\n",
        "    cos_sim = F.cosine_similarity(y_d_pred, y_d_true).mean().item()\n",
        "    metrics[\"disease_cosine_similarity\"] = cos_sim\n",
        "\n",
        "    print(\"\\n======= Evaluation Results =======\")\n",
        "    for k,v in metrics.items():\n",
        "        print(f\"{k:25s}: {v}\")\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "UfQA9k-XFB1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# ======================================================================\n",
        "# HELPER: Node-Level Attention (Eq. 2–5)\n",
        "# ======================================================================\n",
        "class NodeLevelAttention(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.K = num_heads\n",
        "        self.out_dim = out_dim\n",
        "\n",
        "        # Attention vector aΦ in Eq (3)\n",
        "        self.att = nn.Parameter(torch.randn(num_heads, 2 * out_dim))\n",
        "\n",
        "        # Final activation σ(·)\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, h_proj, neighbor_dict, device):\n",
        "        \"\"\"\n",
        "        h_proj: (N, out_dim)\n",
        "        neighbor_dict: dict[i] = list of neighbors j for the meta-path Φ\n",
        "        \"\"\"\n",
        "        N = h_proj.size(0)\n",
        "        all_heads = []\n",
        "\n",
        "        for k in range(self.K):\n",
        "            h_head = []\n",
        "\n",
        "            # For each node compute node-level attention for its neighbors\n",
        "            for i in range(N):\n",
        "                neigh = neighbor_dict[i]\n",
        "                if len(neigh) == 0:\n",
        "                    h_head.append(h_proj[i])\n",
        "                    continue\n",
        "\n",
        "                # Prepare tensor\n",
        "                h_i = h_proj[i].repeat(len(neigh), 1)\n",
        "                h_j = h_proj[neigh]\n",
        "\n",
        "                # Concatenate [h_i || h_j]\n",
        "                concat = torch.cat([h_i, h_j], dim=1)\n",
        "\n",
        "                # e_{i,j} = σ(aᵀ [h_i || h_j])   (Eq. 3 numerator)\n",
        "                e_ij = self.act(torch.matmul(concat, self.att[k].unsqueeze(1))).squeeze()\n",
        "\n",
        "                # α_{i,j} = softmax(e_{i,j}) (Eq. 3)\n",
        "                alpha = torch.softmax(e_ij, dim=0)\n",
        "\n",
        "                # z_i^Φ = σ(sum_j α_{i,j} * h'_j) (Eq. 4)\n",
        "                z_i = torch.sum(alpha.unsqueeze(1) * h_j, dim=0)\n",
        "                h_head.append(z_i)\n",
        "\n",
        "            h_head = torch.stack(h_head)\n",
        "            all_heads.append(h_head)\n",
        "\n",
        "        # Eq. 5 → concatenate multiple heads\n",
        "        z_phi = torch.cat(all_heads, dim=1)  # (N, K*out_dim)\n",
        "        return z_phi\n",
        "\n",
        "\n",
        "# ======================================================================\n",
        "# HELPER: Semantic-Level Attention (Eq. 6–8)\n",
        "# ======================================================================\n",
        "class SemanticAttention(nn.Module):\n",
        "    def __init__(self, in_dim, att_dim=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.W = nn.Linear(in_dim, att_dim)\n",
        "        self.q = nn.Parameter(torch.randn(att_dim))\n",
        "\n",
        "    def forward(self, Z_list):\n",
        "        \"\"\"\n",
        "        Z_list = list of embeddings from each meta-path\n",
        "        \"\"\"\n",
        "        meta_path_weights = []\n",
        "        for Z in Z_list:\n",
        "            # w_Φ = average over nodes qᵀ tanh(W zᵢ)  (Eq. 7)\n",
        "            h = torch.tanh(self.W(Z))\n",
        "            w_phi = torch.mean(torch.matmul(h, self.q))\n",
        "            meta_path_weights.append(w_phi)\n",
        "\n",
        "        # β_Φ = softmax(w_Φ) (Eq. 8)\n",
        "        beta = torch.softmax(torch.stack(meta_path_weights), dim=0)\n",
        "\n",
        "        # Fuse final embedding Z = sum β_Φ * Z_Φ  (Algorithm 1 step 14)\n",
        "        Z_final = sum(beta[i] * Z_list[i] for i in range(len(Z_list)))\n",
        "\n",
        "        return Z_final, beta.detach().cpu()\n",
        "\n",
        "\n",
        "# ======================================================================\n",
        "# HAN MODEL (Algorithm 1)\n",
        "# ======================================================================\n",
        "class HAN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 node_types,\n",
        "                 in_dims,             # dict: node_type → input dimension\n",
        "                 hidden_dim=64,\n",
        "                 out_dim=64,\n",
        "                 num_heads=8,\n",
        "                 meta_paths=[]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.node_types = node_types\n",
        "        self.meta_paths = meta_paths\n",
        "        self.K = num_heads\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # M_φ : type-specific projection (Eq. 1)\n",
        "        self.type_transforms = nn.ModuleDict({\n",
        "            ntype: nn.Linear(in_dims[ntype], hidden_dim)\n",
        "            for ntype in node_types\n",
        "        })\n",
        "\n",
        "        # Node-level attentions for each meta-path\n",
        "        self.node_level = nn.ModuleList([\n",
        "            NodeLevelAttention(hidden_dim, hidden_dim, num_heads)\n",
        "            for _ in meta_paths\n",
        "        ])\n",
        "\n",
        "        # Semantic-level attention\n",
        "        self.semantic_att = SemanticAttention(hidden_dim * num_heads)\n",
        "\n",
        "        # Final classifier head\n",
        "        self.classifier = nn.Linear(hidden_dim * num_heads, 2)\n",
        "\n",
        "    def forward(self, features, meta_neighbors):\n",
        "        \"\"\"\n",
        "        features: dict[node_type] = tensor\n",
        "        meta_neighbors: list of dicts for each meta-path\n",
        "        \"\"\"\n",
        "        # ---------------------------------------------------------------\n",
        "        # Step 1: Type-specific projection (Eq. 1)\n",
        "        # ---------------------------------------------------------------\n",
        "        all_nodes = list(features.values())[0].size(0)\n",
        "        h_proj = torch.zeros((all_nodes, self.hidden_dim),device=next(self.parameters()).device)\n",
        "\n",
        "        for ntype, feat in features.items():\n",
        "            h_proj += self.type_transforms[ntype](feat)\n",
        "\n",
        "        # ---------------------------------------------------------------\n",
        "        # Step 2: Node-level attention for each meta-path\n",
        "        # ---------------------------------------------------------------\n",
        "        Z_meta = []\n",
        "        for mp_idx, neigh_dict in enumerate(meta_neighbors):\n",
        "            Z_phi = self.node_level[mp_idx](h_proj, neigh_dict)\n",
        "            Z_meta.append(Z_phi)\n",
        "\n",
        "        # ---------------------------------------------------------------\n",
        "        # Step 3: Semantic-level fusion (Eq. 7–8)\n",
        "        # ---------------------------------------------------------------\n",
        "        Z_final, beta = self.semantic_att(Z_meta)\n",
        "\n",
        "        # ---------------------------------------------------------------\n",
        "        # Step 4: Final classification\n",
        "        # ---------------------------------------------------------------\n",
        "        logits = self.classifier(Z_final)\n",
        "        return logits, Z_final, beta\n"
      ],
      "metadata": {
        "id": "w2aGf2GWd2be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_PATH = '/content/patient_reports.csv'\n",
        "FILE_PATH_2 = '/content/enhanced_symptom_connectivity_analysis(Sheet1).csv'\n",
        "\n",
        "# Read the data, separating by spaces/tabs\n",
        "#df_2 = pd.read_csv(pd.io.common.StringIO(raw_data), sep='\\t', parse_dates=['ReportDate'])\n",
        "\n",
        "try:\n",
        "    # Use pandas read_csv to load the file\n",
        "    # We keep sep='\\t' (tab) based on your original data format, and parse dates.\n",
        "    df = pd.read_csv(\n",
        "        FILE_PATH,\n",
        "        sep=',',\n",
        "        parse_dates=[\"ReportDate\"],\n",
        "        skipinitialspace=True\n",
        "    )\n",
        "# CRITICAL FIX: Explicitly strip whitespace from column names\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # Verify column existence post-stripping (optional debug)\n",
        "    #if 'ReportDate' not in df.columns:\n",
        "    #    raise ValueError(f\"Column 'ReportDate' not found even after stripping names. Found: {df.columns.tolist()}\")\n",
        "\n",
        "    print(f\"[INFO] Successfully loaded data from {FILE_PATH}. Total rows: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"[ERROR] The file {FILE_PATH} was not found. Please check the file path.\")\n",
        "    # Exit or create an empty DataFrame to prevent crashes\n",
        "    df = pd.DataFrame(columns=['PatientID', 'ReportDate', 'TestName', 'TestValue'])\n",
        "\n",
        "# ---------------------------------------\n",
        "\n",
        "try:\n",
        "    # Use pandas read_csv to load the file\n",
        "    # We keep sep='\\t' (tab) based on your original data format, and parse dates.\n",
        "    df2 = pd.read_csv(\n",
        "        FILE_PATH_2,\n",
        "        sep=',',\n",
        "        #parse_dates=[\"Unique_Patient_Count\"],\n",
        "        encoding='latin-1',\n",
        "        skipinitialspace=True\n",
        "    )\n",
        "# CRITICAL FIX: Explicitly strip whitespace from column names\n",
        "    df2.columns = df2.columns.str.strip()\n",
        "\n",
        "    # Verify column existence post-stripping (optional debug)\n",
        "    #if 'ReportDate' not in df.columns:\n",
        "    #    raise ValueError(f\"Column 'ReportDate' not found even after stripping names. Found: {df.columns.tolist()}\")\n",
        "    if 'Unique_Patient_Count' in df2.columns:\n",
        "        df2['Unique_Patient_Count'] = pd.to_numeric(df2['Unique_Patient_Count'], errors='coerce').astype('Int64')\n",
        "\n",
        "\n",
        "    print(f\"[INFO] Successfully loaded data from {FILE_PATH_2}. Total rows: {len(df2)}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"[ERROR] The file {FILE_PATH_2} was not found. Please check the file path.\")\n",
        "    # Exit or create an empty DataFrame to prevent crashes\n",
        "    df = pd.DataFrame(columns=['TestName', 'Unique_Patient_Count', 'Most_Relevant_Disease', 'Target_Organ'])\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------\n",
        "\n",
        "# Get a map of all unique medical concepts (TestNames)\n",
        "unique_patients = df['PatientID'].unique()\n",
        "unique_concepts = df['TestName'].unique()\n",
        "unique_organs = df2['Target_Organ'].unique()\n",
        "unique_diseases = df2['Most_Relevant_Disease'].unique()\n",
        "ORGAN_MAP = {name: i for i, name in enumerate(unique_organs)}\n",
        "NUM_ORGANS = len(ORGAN_MAP)\n",
        "CONCEPT_MAP = {name: i for i, name in enumerate(unique_concepts)}\n",
        "NUM_CONCEPTS = len(CONCEPT_MAP)\n",
        "DISEASE_MAP = {name: i for i, name in enumerate(unique_diseases)}\n",
        "NUM_DISEASES = len(DISEASE_MAP)\n",
        "PATIENT_IDS = list(unique_patients)\n",
        "PATIENT_IDX_MAP = {id: i for i, id in enumerate(PATIENT_IDS)}\n",
        "VALUE_DIM = 1 # Assuming only one value feature per concept (the normalized value)\n",
        "\n",
        "# Define dimensions\n",
        "INPUT_DIM = NUM_CONCEPTS * VALUE_DIM\n",
        "print(INPUT_DIM)\n",
        "OUTPUT_DIM = 128 # The target h_patient^0 size for the GNN\n",
        "HIDDEN_DIM = 64\n",
        "LSTM_LAYERS = 1\n",
        "TCN_LAYERS = 2\n",
        "TCN_KERNEL = 2\n",
        "TCN_DROPOUT = 0.2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_patient_embeddings(patient_data: pd.DataFrame):\n",
        "    \"\"\"Generates embeddings using both simple aggregation and LSTM methods.\"\"\"\n",
        "\n",
        "    # Initialize the LSTM encoder model\n",
        "    #lstm_encoder = TimeSeriesEncoder(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "    tcn_encoder = TCNEncoder(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM, TCN_LAYERS, TCN_KERNEL, TCN_DROPOUT)\n",
        "    patient_features_dict = {}\n",
        "    # DUMMY PROJECTION layer for the simple_aggregate_visits baseline\n",
        "    # In a real setup, this is part of the training process, not an arbitrary dummy\n",
        "    DUMMY_PROJ_LAYER = nn.Linear(INPUT_DIM, OUTPUT_DIM)\n",
        "\n",
        "    #results = {'simple_aggregate': {}, 'lstm_encoder': {}, 'tcn_encoder': {}}\n",
        "\n",
        "    for patient_id, group in patient_data.groupby('PatientID'):\n",
        "        #print(f\"\\nProcessing Patient: {patient_id}\")\n",
        "\n",
        "        # --- Step 1: Data Transformation ---\n",
        "        group = group.sort_values('ReportDate')\n",
        "\n",
        "        # Transform sparse EMR records into a dense feature sequence tensor\n",
        "        visit_features_sequence = transform_raw_to_features(group, CONCEPT_MAP, VALUE_DIM)\n",
        "        h_p_0 = None\n",
        "\n",
        "        if visit_features_sequence.size(0) >= TCN_KERNEL:\n",
        "            with torch.no_grad():\n",
        "                ts_input = visit_features_sequence.unsqueeze(0)\n",
        "                patient_features_dict[patient_id] = tcn_encoder(ts_input).squeeze(0)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                patient_features_dict[patient_id] = simple_aggregate_visits(visit_features_sequence, OUTPUT_DIM)\n",
        "\n",
        "\n",
        "        #print(f\"  Sequence Length: {visit_features_sequence.size(0)}\")\n",
        "        #print(f\"  Feature Dim (per visit): {visit_features_sequence.size(1)}\")\n",
        "\n",
        "\n",
        "        # --- Step 2: Apply Simple Aggregation (Baseline) ---\n",
        "        # NOTE: Using the DUMMY_PROJ_LAYER defined above\n",
        "        with torch.no_grad():\n",
        "            simple_embed = simple_aggregate_visits(visit_features_sequence, OUTPUT_DIM)\n",
        "\n",
        "        #results['simple_aggregate'][patient_id] = simple_embed\n",
        "        #print(f\"  Simple Aggregation h_0 shape: {simple_embed.shape}\")\n",
        "\n",
        "        # --- Step 3: Apply LSTM Encoder ---\n",
        "        with torch.no_grad():\n",
        "            # Add batch dimension: (1, sequence_length, input_dim)\n",
        "            ts_input = visit_features_sequence.unsqueeze(0)\n",
        "            #lstm_embed = lstm_encoder(ts_input).squeeze(0) # Remove batch dimension\n",
        "\n",
        "        #results['lstm_encoder'][patient_id] = lstm_embed\n",
        "        #print(f\"  LSTM Encoder h_0 shape: {lstm_embed.shape}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            tcn_embed = tcn_encoder(ts_input).squeeze(0)\n",
        "        #results['tcn_encoder'][patient_id] = tcn_embed\n",
        "        #print(f\"  TCN Encoder h_0 shape: {tcn_embed.shape}\")\n",
        "    # Filter patient IDs to only include those successfully encoded\n",
        "    final_patient_ids = list(patient_features_dict.keys())\n",
        "    final_patient_idx_map = {id: i for i, id in enumerate(final_patient_ids)}\n",
        "\n",
        "    print(f\"\\n--- Stage 1: Feature Generation Complete ---\")\n",
        "    print(f\"Total Patients Encoded: {len(final_patient_ids)}\")\n",
        "    print(f\"Final Patient Feature Dimension (h_p^0): {OUTPUT_DIM}\")\n",
        "\n",
        "    print(\"\\n--- First 5 items in patient_feature_dict ---\")\n",
        "    for i, (k, v) in enumerate(patient_features_dict.items()):\n",
        "      if i == 5:\n",
        "          break\n",
        "      print(f\"Patient ID: {k} -> Features: {v[:10]} ...\")\n",
        "\n",
        "\n",
        "    sample_key = next(iter(patient_features_dict))\n",
        "    print(\"\\nSample patient key:\", sample_key)\n",
        "    print(\"Feature vector:\", patient_features_dict[sample_key])\n",
        "    print(\"Length:\", len(patient_features_dict[sample_key]))\n",
        "\n",
        "    return patient_features_dict, final_patient_ids, final_patient_idx_map\n",
        "\n",
        "\n",
        "def build_and_get_unified_graph():\n",
        "\n",
        "\n",
        "    final_unified_graph = construct_final_unified_graph(\n",
        "        ps_graph, so_graph, od_graph, data_obj\n",
        "    )\n",
        "\n",
        "    return final_unified_graph, final_patient_ids # Return the built graph object\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(f\"Total Unique Medical Concepts (Input Dim): {NUM_CONCEPTS} (x{VALUE_DIM})\\n\")\n",
        "\n",
        "    patient_features_dict, final_patient_ids, final_patient_idx_map = generate_patient_embeddings(df)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"COMPARISON OF GENERATED PATIENT EMBEDDINGS (h_patient^0)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    patient_symptom_edges = identify_patient_symptom_relations(df)\n",
        "    symptom_organ_edges = identify_organ_symptom_relations(df2)\n",
        "    organ_disease_edges = identify_organ_disease_relations(df2)\n",
        "    ps_graph = construct_patient_symptom_bipartite_graph(\n",
        "        final_patient_ids,\n",
        "        patient_features_dict,\n",
        "        final_patient_idx_map,\n",
        "        CONCEPT_MAP,\n",
        "        patient_symptom_edges\n",
        "    )\n",
        "\n",
        "# 4. FINAL VERIFICATION\n",
        "    print(\"\\n--- Stage 2: Patient-Symptom Graph Constructed ---\")\n",
        "    #print(ps_graph)\n",
        "\n",
        "    so_graph = construct_symptom_organ_graph(\n",
        "        CONCEPT_MAP,\n",
        "        ORGAN_MAP,\n",
        "        symptom_organ_edges\n",
        "    )\n",
        "    print(\"\\n--- Stage 2: Symptom-organ Graph Constructed ---\")\n",
        "    print(so_graph)\n",
        "\n",
        "\n",
        "    od_graph = construct_disease_organ_graph(\n",
        "        DISEASE_MAP,\n",
        "        ORGAN_MAP,\n",
        "        organ_disease_edges\n",
        "    )\n",
        "    print(\"\\n--- Stage 2: Disease-organ Graph Constructed ---\")\n",
        "    print(od_graph)\n",
        "\n",
        "\n",
        "    PATIENT_LABELS = {id: torch.randint(0, 2, (NUM_DISEASES,)).float() for id in final_patient_ids}\n",
        "\n",
        "    data_obj = PatientData(patient_features_dict,final_patient_ids, final_patient_idx_map, CONCEPT_MAP, DISEASE_MAP, ORGAN_MAP, patient_symptom_edges, symptom_organ_edges, organ_disease_edges,PATIENT_LABELS)\n",
        "\n",
        "\n",
        "    # --- C. MERGE ALL GRAPHS (Integration Layer) ---\n",
        "    final_unified_graph,_ = build_and_get_unified_graph()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"GNN INPUT READY\")\n",
        "    print(final_unified_graph)\n",
        "    print(f\"Total Edges for GNN: {final_unified_graph.num_edges}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "\n",
        "    metadata = final_unified_graph.metadata()\n",
        "    print(\"\\n--- DEBUG: Graph Metadata Schema Check ---\")\n",
        "    print(f\"Node Types Passed to Model: {metadata[0]}\")\n",
        "    print(f\"Edge Types Passed to Model: {metadata[1]}\")\n",
        "\n",
        "\n",
        "    metapaths = extract_metapaths(metadata)\n",
        "\n",
        "    # 1. Extract node types\n",
        "    node_types = final_unified_graph.metadata()[0]\n",
        "\n",
        "# 2. Extract input feature dims automatically\n",
        "    in_dims = {ntype: final_unified_graph[ntype].x.shape[1] for ntype in node_types}\n",
        "\n",
        "    print(\"Detected metapaths:\")\n",
        "    for m in metapaths:\n",
        "      print(m)\n",
        "\n",
        "    num_diseases_final = final_unified_graph['disease'].x.shape[0] # This should give 64\n",
        "    print(f\"Number of Disease Nodes in Final Graph: {num_diseases_final} (Expected: {len(DISEASE_MAP)})\")\n",
        "\n",
        "    import torch\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    model = HAN(\n",
        "        node_types=node_types,\n",
        "        in_dims=in_dims,\n",
        "        hidden_dim=64,\n",
        "        out_dim=OUTPUT_DIM,\n",
        "        num_heads=8,\n",
        "        meta_paths=metapaths\n",
        "    ).to(device)\n",
        "\n",
        "    hgat_model = DiseasePredictionModelHGAT(\n",
        "        data_metadata=metadata,\n",
        "        embedding_dim=OUTPUT_DIM,\n",
        "        num_diseases=num_diseases_final\n",
        "    )\n",
        "\n",
        "    han_model = DiseasePredictionModelHAN(\n",
        "        metadata=metadata,\n",
        "        metapaths=metapaths,\n",
        "        embedding_dim=OUTPUT_DIM,\n",
        "        num_diseases=num_diseases_final\n",
        "    )\n",
        "\n",
        "\n",
        "    # Move graph data to device\n",
        "    for k in final_unified_graph.x_dict:\n",
        "        final_unified_graph.x_dict[k] = final_unified_graph.x_dict[k].to(device)\n",
        "    for k in final_unified_graph.edge_index_dict:\n",
        "        final_unified_graph.edge_index_dict[k] = final_unified_graph.edge_index_dict[k].to(device)\n",
        "\n",
        "    final_unified_graph['patient'].y = final_unified_graph['patient'].y.to(device)\n",
        "    final_unified_graph['disease'].y_identity = final_unified_graph['disease'].y_identity.to(device)\n",
        "\n",
        "\n",
        "    trained_model_HAN = train(model, final_unified_graph)\n",
        "    #print(\"\\n HAN model  training..........\")\n",
        "    #HAN_trained_model = train_hgan_model(han_model, final_unified_graph, epochs=50, lr=0.0005)\n",
        "\n",
        "    # 2. Start Training Simulation\n",
        "    #print(\"\\n HGT model  training..........\")\n",
        "    #trained_model = train_hgat_model(hgat_model, final_unified_graph, epochs=50, lr=0.0005)\n",
        "\n",
        "    #print(\"\\n[RESEARCH PHASE] The HGAT and HAN models are now trained and ready for comparison.\")\n",
        "\n",
        "    #print(\"\\nEvaluating HGAT Model...\")\n",
        "    #hgat_results = evaluate_model(trained_model, final_unified_graph)\n",
        "\n",
        "    print(\"\\nEvaluating HAN Model...\")\n",
        "    han_results = evaluate_model(trained_model_HAN, final_unified_graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "RAFIiIoht32e",
        "outputId": "04ff9ca4-2a00-4357-ad87-4117757937c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Successfully loaded data from /content/patient_reports.csv. Total rows: 160942\n",
            "[INFO] Successfully loaded data from /content/enhanced_symptom_connectivity_analysis(Sheet1).csv. Total rows: 176\n",
            "177\n",
            "Total Unique Medical Concepts (Input Dim): 177 (x1)\n",
            "\n",
            "\n",
            "--- Stage 1: Feature Generation Complete ---\n",
            "Total Patients Encoded: 24352\n",
            "Final Patient Feature Dimension (h_p^0): 128\n",
            "\n",
            "--- First 5 items in patient_feature_dict ---\n",
            "Patient ID: 139760 -> Features: tensor([0.0367, 0.0000, 0.0000, 0.0000, 0.0606, 0.0000, 0.0711, 0.0000, 0.0239,\n",
            "        0.0000]) ...\n",
            "Patient ID: 200041 -> Features: tensor([0.0187, 0.0000, 0.0000, 0.0000, 0.0275, 0.0000, 0.0765, 0.0000, 0.0285,\n",
            "        0.0294]) ...\n",
            "Patient ID: 201519 -> Features: tensor([0.0000, 0.0000, 0.0131, 0.0000, 0.0000, 0.0602, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) ...\n",
            "Patient ID: 201605 -> Features: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0474, 0.0000, 0.0778, 0.0000, 0.0000,\n",
            "        0.0588]) ...\n",
            "Patient ID: 201839 -> Features: tensor([0.0206, 0.0423, 0.0225, 0.0000, 0.0172, 0.0636, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) ...\n",
            "\n",
            "Sample patient key: 139760\n",
            "Feature vector: tensor([0.0367, 0.0000, 0.0000, 0.0000, 0.0606, 0.0000, 0.0711, 0.0000, 0.0239,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0495, 0.0824, 0.0000, 0.0000, 0.0000,\n",
            "        0.1672, 0.0000, 0.1466, 0.0000, 0.0413, 0.0713, 0.0000, 0.1025, 0.0190,\n",
            "        0.1399, 0.0688, 0.0000, 0.0255, 0.0321, 0.0000, 0.0000, 0.0000, 0.1591,\n",
            "        0.0617, 0.1501, 0.1077, 0.0000, 0.1065, 0.0000, 0.0000, 0.0818, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0644, 0.1716, 0.0858, 0.0000, 0.0499,\n",
            "        0.0000, 0.0787, 0.0102, 0.0000, 0.0000, 0.0000, 0.0421, 0.0685, 0.0000,\n",
            "        0.0517, 0.0000, 0.0000, 0.0000, 0.0013, 0.0338, 0.0000, 0.0000, 0.1650,\n",
            "        0.0569, 0.0096, 0.1615, 0.0559, 0.0071, 0.0541, 0.0927, 0.0912, 0.0340,\n",
            "        0.0000, 0.1280, 0.0690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0374, 0.0315,\n",
            "        0.0000, 0.0000, 0.0000, 0.0549, 0.0082, 0.0000, 0.0000, 0.0380, 0.0152,\n",
            "        0.0228, 0.0856, 0.0000, 0.0000, 0.0000, 0.0957, 0.0506, 0.0000, 0.0000,\n",
            "        0.0042, 0.0404, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0761, 0.0000, 0.0980, 0.1051,\n",
            "        0.0864, 0.1448])\n",
            "Length: 128\n",
            "\n",
            "==================================================\n",
            "COMPARISON OF GENERATED PATIENT EMBEDDINGS (h_patient^0)\n",
            "==================================================\n",
            "\n",
            "--- Relationship Identification ---\n",
            "Total Unique Patients (Nodes): 24352\n",
            "Total Unique Symptoms (Nodes): 177\n",
            "\n",
            "[Relationship 1: Patient <-> Symptom (P Graph)]\n",
            "Total unique Patient-Symptom links (edges): 157765\n",
            "Example Links and Frequencies:\n",
            "   PatientID                              TestName  Frequency\n",
            "0     139760                            ALP Result          1\n",
            "1     139760                         ASOT  Result           1\n",
            "2     139760                     Blood Urea Result          1\n",
            "3     200041            1 Hr After Plasma Glucose           2\n",
            "4     200041  2 Hr After Breakfast Plasma Glucose           1\n",
            "\n",
            "--- Relationship Identification ---\n",
            "Total Unique Organs (Nodes): 26\n",
            "Total Unique Symptoms (Nodes): 176\n",
            "\n",
            "[Relationship 1: Organ <-> Symptom (SO Graph)]\n",
            "Total unique Organ-Symptom links (edges): 175\n",
            "Example Links and Frequencies:\n",
            "  Target_Organ                     TestName  Frequency\n",
            "0        Blood   1 Hr After Plasma Glucose           1\n",
            "1        Blood  2 Hrs After Plasma Glucose           1\n",
            "2        Blood           Basophils# % Value          1\n",
            "3        Blood    Basophils# Absolute Value          1\n",
            "4        Blood         Bleeding Time Result          1\n",
            "\n",
            "--- Relationship Identification ---\n",
            "Total Unique Organs (Nodes): 26\n",
            "Total Unique diseases (Nodes): 64\n",
            "\n",
            "[Relationship 1: Organ <-> Disease (OD Graph)]\n",
            "Total unique Organ-Disease links (edges): 71\n",
            "Example Links and Frequencies:\n",
            "  Target_Organ    Most_Relevant_Disease  Frequency\n",
            "0        Blood        Allergies/ asthma          2\n",
            "1        Blood                   Anemia          7\n",
            "2        Blood      Anemia (B12/folate)          1\n",
            "3        Blood       Anemia/Dehydration          1\n",
            "4        Blood  Cardiovascular Diseases          1\n",
            "\n",
            "Top 3 Patients by total symptom records (Hubs): \n",
            "Target_Organ\n",
            "Blood     43\n",
            "kidney    37\n",
            "Liver     21\n",
            "Name: Frequency, dtype: int64\n",
            "[SUCCESS] Built 157765 P->S edges.\n",
            "\n",
            "--- Stage 2: Patient-Symptom Graph Constructed ---\n",
            "[SUCCESS] Symptom -> Organ Graph built with 174 edges.\n",
            "\n",
            "--- Stage 2: Symptom-organ Graph Constructed ---\n",
            "HeteroData(\n",
            "  symptom={ num_nodes=177 },\n",
            "  organ={ num_nodes=26 },\n",
            "  (symptom, measures, organ)={ edge_index=[2, 174] }\n",
            ")\n",
            "[SUCCESS] Disease -> Organ Graph built with 71 edges.\n",
            "\n",
            "--- Stage 2: Disease-organ Graph Constructed ---\n",
            "HeteroData(\n",
            "  disease={ num_nodes=64 },\n",
            "  organ={ num_nodes=26 },\n",
            "  (organ, is affected, disease)={ edge_index=[2, 71] }\n",
            ")\n",
            "\n",
            "--- DEBUG: Graph Integration Verification ---\n",
            "  Node Type PATIENT: 24352 [OK]\n",
            "  Node Type SYMPTOM: 177 [OK]\n",
            "  Node Type DISEASE: 64 [OK]\n",
            "  Node Type ORGAN: 26 [OK]\n",
            "  Edge Type HAS: 157765 [OK]\n",
            "  Edge Type IS_RELATED_TO: 157765 [OK]\n",
            "  Edge Type MEASURES: 174 [FAIL] Expected 175\n",
            "  Edge Type IS AFFECTED: 71 [OK]\n",
            "  TOTAL Edges Unified: 315775\n",
            "---------------------------------------\n",
            "\n",
            "======================================================================\n",
            "GNN INPUT READY\n",
            "HeteroData(\n",
            "  patient={\n",
            "    x=[24352, 128],\n",
            "    y=[24352, 64],\n",
            "  },\n",
            "  symptom={ x=[177, 128] },\n",
            "  disease={\n",
            "    x=[64, 128],\n",
            "    y_identity=[64, 64],\n",
            "  },\n",
            "  organ={ x=[26, 128] },\n",
            "  (patient, has, symptom)={ edge_index=[2, 157765] },\n",
            "  (symptom, is_related_to, patient)={ edge_index=[2, 157765] },\n",
            "  (symptom, measures, organ)={ edge_index=[2, 174] },\n",
            "  (organ, is affected, disease)={ edge_index=[2, 71] }\n",
            ")\n",
            "Total Edges for GNN: 315775\n",
            "======================================================================\n",
            "\n",
            "--- DEBUG: Graph Metadata Schema Check ---\n",
            "Node Types Passed to Model: ['patient', 'symptom', 'disease', 'organ']\n",
            "Edge Types Passed to Model: [('patient', 'has', 'symptom'), ('symptom', 'is_related_to', 'patient'), ('symptom', 'measures', 'organ'), ('organ', 'is affected', 'disease')]\n",
            "Detected metapaths:\n",
            "[('patient', 'has', 'symptom'), ('symptom', 'is_related_to', 'patient')]\n",
            "[('patient', 'has', 'symptom'), ('symptom', 'measures', 'organ')]\n",
            "[('symptom', 'is_related_to', 'patient'), ('patient', 'has', 'symptom')]\n",
            "[('symptom', 'measures', 'organ'), ('organ', 'is affected', 'disease')]\n",
            "Number of Disease Nodes in Final Graph: 64 (Expected: 64)\n",
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-406958773.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mtrained_model_HAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_unified_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;31m#print(\"\\n HAN model  training..........\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m#HAN_trained_model = train_hgan_model(han_model, final_unified_graph, epochs=50, lr=0.0005)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4266413185.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, epochs, lr, device)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1038044516.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, meta_neighbors)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Step 1: Type-specific projection (Eq. 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# ---------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mall_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mh_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6d_Du_omAnLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6AP4kFL2WRvi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}