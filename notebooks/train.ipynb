{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc37087",
   "metadata": {},
   "source": [
    "# pyHGT Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350fb23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a49b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87671101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.5\n",
      "c:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\matplotlib\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)\n",
    "print(matplotlib.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96d7c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.0\n",
      "c:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\seaborn\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import seaborn, inspect\n",
    "print(seaborn.__version__)\n",
    "print(seaborn.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceacb05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\FYP\\CODE\\pyHGT-implementation\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93bd727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyHGT\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Graph, sample_subgraph, to_torch\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyHGT\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GNN, Classifier\n\u001b[0;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\FYP\\CODE\\pyHGT-implementation\\pyHGT\\model.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClassifier\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_hid, n_out):\n",
      "File \u001b[1;32md:\\FYP\\CODE\\pyHGT-implementation\\pyHGT\\conv.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GCNConv, GATConv\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessagePassing\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glorot, uniform\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\torch_geometric\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_debug_enabled, debug, set_debug\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\torch_geometric\\nn\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetaLayer\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Reshape\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\torch_geometric\\nn\\data_parallel.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chain\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Batch\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDataParallel\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel):\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Implements data parallelism at the module level.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    This container parallelizes the application of the given :attr:`module` by\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m            vectors for each key in the list. (default: :obj:`[]`)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\torch_geometric\\data\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Batch\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\torch_geometric\\data\\data.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_sparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coalesce, SparseTensor\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (contains_isolated_nodes,\n\u001b[0;32m     10\u001b[0m                                    contains_self_loops, is_undirected)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnum_nodes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m maybe_num_nodes\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\torch_sparse\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m spec \u001b[38;5;241m=\u001b[39m cuda_spec \u001b[38;5;129;01mor\u001b[39;00m cpu_spec\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\site-packages\\torch\\_ops.py:105\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    100\u001b[0m path \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[1;32mc:\\Users\\Anushka\\miniconda3\\envs\\pyhgt38\\lib\\ctypes\\__init__.py:373\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from pyHGT.data import Graph, sample_subgraph, to_torch\n",
    "from pyHGT.model import GNN, Classifier\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd CODE/pyHGT-implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data files\n",
    "\n",
    "data_dir = 'data/'\n",
    "\n",
    "patient_tests = pd.read_csv(os.path.join(data_dir,\"patient-test.csv\"), encoding='latin1')\n",
    "test_details = pd.read_csv(os.path.join(data_dir,\"test-disease-organ.csv\"), encoding='latin1')\n",
    "labels_df = pd.read_csv(os.path.join(data_dir,\"patient-one-hot-labeled-disease.csv\"), encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904d7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(patient_tests.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ffe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test_details.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde101b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_tests[\"patient_id\"] = patient_tests[\"patient_id\"].astype(str)\n",
    "patient_tests[\"test_name\"] = patient_tests[\"test_name\"].astype(str)\n",
    "\n",
    "test_details[\"test_name\"] = test_details[\"test_name\"].astype(str)\n",
    "\n",
    "if \"organ\" in test_details.columns:\n",
    "    test_details[\"organ\"] = test_details[\"organ\"].astype(str)\n",
    "\n",
    "if \"disease\" in test_details.columns:\n",
    "    test_details[\"disease\"] = test_details[\"disease\"].astype(str)\n",
    "\n",
    "test_details = test_details.drop_duplicates(subset=[\"test_name\"]).reset_index(drop=True)\n",
    "\n",
    "#temporal processing\n",
    "patient_tests[\"report_date\"] = pd.to_datetime(patient_tests[\"report_date\"])\n",
    "patient_tests[\"time_idx\"] = patient_tests[\"report_date\"].astype(\"int64\") // 10**9  # convert to unix timestamp in seconds\n",
    "\n",
    "min_time = patient_tests[\"time_idx\"].min()\n",
    "patient_tests[\"rel_time\"] = (patient_tests[\"time_idx\"]-min_time)// 86400  # convert to days\n",
    "\n",
    "max_rel_time = int(patient_tests[\"rel_time\"].max())\n",
    "print(\"max_rel_time =\", max_rel_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b650a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(patient_tests.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032bf1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_multi(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    x = str(x).strip()\n",
    "\n",
    "    if \";\" in x:\n",
    "        return [item.strip() for item in x.split(\";\")]\n",
    "    \n",
    "    if \",\" in x:\n",
    "        return [item.strip() for item in x.split(\",\")]\n",
    "    \n",
    "    return [x] if x else []\n",
    "\n",
    "\n",
    "lab_info = {}\n",
    "\n",
    "for _, row in test_details.iterrows():\n",
    "    test = str(row[\"test_name\"]).strip()\n",
    "\n",
    "    organs = parse_multi(row.get(\"organ\", \"\"))\n",
    "    diseases = parse_multi(row.get(\"disease\", \"\"))\n",
    "\n",
    "    low_th = None\n",
    "    high_th = None\n",
    "    if \"min\" in row and not pd.isna(row[\"min\"]):\n",
    "        low_th = float(row[\"min\"])\n",
    "    if \"max\" in row and not pd.isna(row[\"max\"]):\n",
    "        high_th = float(row[\"max\"])\n",
    "\n",
    "    lab_info[test] = {\n",
    "        \"organs\": organs,\n",
    "        \"diseases\": diseases,\n",
    "        \"low\": low_th,\n",
    "        \"high\": high_th\n",
    "    }\n",
    "\n",
    "print(\"example lab info:\", list(lab_info.items())[:3]) # only show 3 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa895b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_merged = patient_tests.merge(\n",
    "    test_details[[\"test_name\", \"min\", \"max\"]],\n",
    "    on=\"test_name\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "def compute_abnoramability(row):\n",
    "    v = float(row[\"test_value\"])\n",
    "    low = row[\"min\"]\n",
    "    high = row[\"max\"]\n",
    "\n",
    "    if pd.isna(low) or pd.isna(high) or low >= high:\n",
    "        return 0.0  # cannot determine abnormality\n",
    "    return float((v - low) / (high - low))\n",
    "\n",
    "\n",
    "pt_merged[\"abnormality\"] = pt_merged.apply(compute_abnoramability, axis=1)\n",
    "\n",
    "# aggregate per person\n",
    "agg = pt_merged.groupby(\"patient_id\").agg(\n",
    "    num_tests = (\"test_name\", \"count\"),\n",
    "    mean_abn = (\"abnormality\", \"mean\"),\n",
    "    max_abn = (\"abnormality\", \"max\"),\n",
    "    min_abn = (\"abnormality\", \"min\"),\n",
    "    last_time = (\"rel_time\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "patient_feat_df = agg.set_index(\"patient_id\")\n",
    "patient_feat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique node ids\n",
    "patient_ids = sorted(patient_tests[\"patient_id\"].astype(str).unique().tolist())\n",
    "lab_tests = sorted(list(lab_info.keys()))\n",
    "\n",
    "all_organs = sorted({org for info in lab_info.values() for org in info[\"organs\"] if org})\n",
    "all_diseases = sorted({dis for info in lab_info.values() for dis in info[\"diseases\"] if dis})\n",
    "\n",
    "print(\"#patients =\", len(patient_ids))\n",
    "print(\"#labs =\", len(lab_tests))\n",
    "print(\"#organs =\", len(all_organs))\n",
    "print(\"#diseases =\", len(all_diseases))\n",
    "\n",
    "print(\"#nodes = \", len(patient_ids) + len(lab_tests) + len(all_organs) + len(all_diseases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe19739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build pyHGT graph - add nodes\n",
    "\n",
    "graph = Graph()\n",
    "\n",
    "for pid in patient_ids:\n",
    "    if pid in patient_feat_df.index:\n",
    "        row = patient_feat_df.loc[pid]\n",
    "        node = {\n",
    "            \"type\": \"patient\",\n",
    "            \"id\": pid,\n",
    "            \"num_tests\": float(row[\"num_tests\"]),\n",
    "            \"mean_abn\":  float(row[\"mean_abn\"]),\n",
    "            \"max_abn\":   float(row[\"max_abn\"]),\n",
    "            \"min_abn\":   float(row[\"min_abn\"]),\n",
    "            \"last_time\": int(row[\"last_time\"]),\n",
    "            \"time\":      int(row[\"last_time\"]),\n",
    "        }\n",
    "    \n",
    "    else:\n",
    "        node = {\n",
    "            \"type\": \"patient\",\n",
    "            \"id\": pid,\n",
    "            \"num_tests\": 0.0,\n",
    "            \"mean_abn\":  0.0,\n",
    "            \"max_abn\":   0.0,\n",
    "            \"min_abn\":   0.0,\n",
    "            \"last_time\": 0,\n",
    "            \"time\":      0,\n",
    "        }\n",
    "    graph.add_node(node)\n",
    "\n",
    "for test in lab_tests:\n",
    "    info = lab_info[test]\n",
    "    graph.add_node({\n",
    "        \"type\": \"lab_test\",\n",
    "        \"id\": test,\n",
    "        \"time\": 0,\n",
    "        \"low\": 0.0 if info[\"low\"] is None else float(info[\"low\"]),\n",
    "        \"high\": 0.0 if info[\"high\"] is None else float(info[\"high\"])\n",
    "    })\n",
    "\n",
    "\n",
    "for organ in all_organs:\n",
    "    graph.add_node({\n",
    "        \"type\": \"organ\",\n",
    "        \"id\": organ,\n",
    "        \"time\": 0\n",
    "    })\n",
    "\n",
    "for disease in all_diseases:\n",
    "    graph.add_node({\n",
    "        \"type\": \"disease\",\n",
    "        \"id\": disease,\n",
    "        \"time\": 0\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience maps from original ID -> internal index\n",
    "patient2idx = graph.node_forward[\"patient\"]\n",
    "lab2idx     = graph.node_forward[\"lab_test\"]\n",
    "organ2idx   = graph.node_forward[\"organ\"]\n",
    "disease2idx = graph.node_forward[\"disease\"]\n",
    "\n",
    "print(\"Example patient2idx:\", list(lab2idx.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build pyHGT graph - add edges with temporal info\n",
    "\n",
    "for _, row in patient_tests.iterrows():\n",
    "    pid = str(row[\"patient_id\"])\n",
    "    test = str(row[\"test_name\"])\n",
    "    t = int(row[\"rel_time\"])\n",
    "\n",
    "    if pid in patient2idx and test in lab2idx: # src and dst nodes exist\n",
    "        # patient - lab_test edge\n",
    "        graph.add_edge(\n",
    "            {\"type\": \"patient\", \"id\": pid},\n",
    "            {\"type\": \"lab_test\", \"id\": test},\n",
    "            time=t,\n",
    "            relation_type=\"had_test\",\n",
    "            directed=True,\n",
    "        )\n",
    "\n",
    "for test, info in lab_info.items():\n",
    "\n",
    "    # lab_test - organ edges\n",
    "    for organ in info[\"organs\"]:\n",
    "        if organ in organ2idx:\n",
    "            graph.add_edge(\n",
    "                {\"type\": \"lab_test\", \"id\": test},\n",
    "                {\"type\": \"organ\", \"id\": organ},\n",
    "                relation_type=\"tests_organ\",\n",
    "                directed=True,\n",
    "                time=0\n",
    "            )\n",
    "\n",
    "    # lab_test - disease edges\n",
    "    for disease in info[\"diseases\"]:\n",
    "        if disease in disease2idx:\n",
    "            graph.add_edge(\n",
    "                {\"type\": \"lab_test\", \"id\": test},\n",
    "                {\"type\": \"disease\", \"id\": disease},\n",
    "                relation_type=\"associated_with\",\n",
    "                directed=True,\n",
    "                time=0\n",
    "            )\n",
    "\n",
    "            for organ in info[\"organs\"]:\n",
    "                if organ in organ2idx:\n",
    "                    graph.add_edge(\n",
    "                        {\"type\": \"disease\", \"id\": disease},\n",
    "                        {\"type\": \"organ\", \"id\": organ},\n",
    "                        relation_type=\"occurs_in\",\n",
    "                        directed=True,\n",
    "                        time=0\n",
    "                    )\n",
    "\n",
    "print(\"Meta relations in graph:\", graph.get_meta_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b52fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node features\n",
    "\n",
    "for t, node_list in graph.node_bacward.items():\n",
    "    df = pd.DataFrame(node_list).reset_index(drop=True)\n",
    "    graph.node_feature[t] = df\n",
    "\n",
    "for t,df in graph.node_feature.items():\n",
    "    print(f\"Node type: {t}, feature shape: {df.shape}\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_medical extractor for sample subgraph\n",
    "\n",
    "def feature_medical(layer_data, graph):\n",
    "    feature = {}\n",
    "    times = {}\n",
    "    indxs = {}\n",
    "    texts = {}\n",
    "\n",
    "    # for t in layer_data:\n",
    "    #     if len(layer_data[t]) == 0:\n",
    "    #         continue\n",
    "\n",
    "    all_types = graph.node_feature.keys()\n",
    "\n",
    "    for t in layer_data:\n",
    "        if len(layer_data[t]) == 0:\n",
    "            # feature[t] = np.zeros((0,5), dtype=np.float32)  # empty features\n",
    "            # times[t] = np.array((0,), dtype=np.int32)\n",
    "            # indxs[t] = np.array((0,), dtype=np.int32)\n",
    "            continue\n",
    "\n",
    "        idxs = np.array(list(layer_data[t].keys()))\n",
    "        tims = np.array(list(layer_data[t].values()))[:,1]\n",
    "\n",
    "        df = graph.node_feature[t]\n",
    "        feats = np.zeros((len(idxs),5), dtype=np.float32)  # 5 features per node\n",
    "\n",
    "        if t == \"patient\":\n",
    "\n",
    "            cols = [\"num_tests\", \"mean_abn\", \"max_abn\", \"min_abn\", \"last_time\"]\n",
    "            vals = df.loc[idxs, cols].fillna(0).values.astype(np.float32)\n",
    "            feats = vals # all 5 features\n",
    "\n",
    "        elif t == \"lab_test\":\n",
    "            for c in [\"low\", \"high\"]:\n",
    "                if c not in df.columns:\n",
    "                    df[c] = 0.0\n",
    "            vals = df.loc[idxs, [\"low\", \"high\"]].fillna(0).values.astype(np.float32)\n",
    "            feats[:,0:2] = vals  # first 2 features and other 3 are zeros\n",
    "\n",
    "        else:\n",
    "            pass  # no features for organ and disease nodes\n",
    "\n",
    "        feature[t] = feats\n",
    "        times[t] = tims\n",
    "        indxs[t] = idxs\n",
    "\n",
    "    return feature, times, indxs, texts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subgraph sampling test\n",
    "\n",
    "from pyHGT.data import sample_subgraph, to_torch\n",
    "\n",
    "all_patient_indices = np.array(list(graph.node_forward[\"patient\"].values()))\n",
    "batch_pids = all_patient_indices[:8] # first 8 patients for testing\n",
    "\n",
    "inp = {\n",
    "    \"patient\": [(int(pid),0) for pid in batch_pids]\n",
    "}\n",
    "\n",
    "feature, times, edge_list, indxs, texts = sample_subgraph(\n",
    "    graph,\n",
    "    time_range={max_rel_time: True},\n",
    "    sampled_depth=2,\n",
    "    sampled_number=8,\n",
    "    inp = inp,\n",
    "    feature_extractor=feature_medical\n",
    ")\n",
    "\n",
    "node_feature, node_type, edge_time, edge_index, edge_type, node_dict, edge_dict = to_torch(\n",
    "    feature,times,edge_list, graph\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"node_feature:\", node_feature.shape)\n",
    "print(\"node_type:\", node_type.shape)\n",
    "print(\"edge_index:\", edge_index.shape)\n",
    "print(\"edge_time:\", edge_time.shape)\n",
    "print(\"edge_type:\", edge_type.shape)\n",
    "print(\"node_dict:\", node_dict)\n",
    "print(\"edge_dict:\", edge_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1b407",
   "metadata": {},
   "source": [
    "### Label Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb651943",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_label_cols = [c for c in labels_df.columns if c != \"patient_id\"]\n",
    "num_diseases = len(disease_label_cols)\n",
    "\n",
    "print(\"Label columns:\", disease_label_cols)\n",
    "print(\"Number of diseases to predict:\", num_diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch tensor for labels\n",
    "\n",
    "num_patients_in_graph = len(patient2idx)\n",
    "Y = torch.zeros((num_patients_in_graph, num_diseases), dtype=torch.float32)\n",
    "\n",
    "for _, row in labels_df.iterrows():\n",
    "    pid = str(row[\"patient_id\"])\n",
    "    if pid in patient2idx:\n",
    "        idx = patient2idx[pid]\n",
    "        Y[idx] = torch.tensor(row[disease_label_cols].values, dtype=torch.float32)\n",
    "\n",
    "print(\"Labels tensor shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285de391",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = graph.get_types()\n",
    "num_types = len(types)\n",
    "\n",
    "meta_rels = graph.get_meta_graph()\n",
    "num_relations = len(meta_rels) + 1\n",
    "\n",
    "print(\"Node types:\", types)\n",
    "print(\"Number of node types:\", num_types)\n",
    "print(\"Meta relations:\", meta_rels)\n",
    "print(\"Number of relations:\", num_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 5\n",
    "hidden_dim = 64\n",
    "n_heads = 4\n",
    "n_layers  =2\n",
    "dropout   = 0.2\n",
    "\n",
    "num_diseases = Y.shape[1]  # number of disease classes\n",
    "\n",
    "gnn = GNN(\n",
    "    in_dim=in_dim,\n",
    "    n_hid=hidden_dim,\n",
    "    num_types=num_types,\n",
    "    num_relations=num_relations,\n",
    "    n_heads=n_heads,\n",
    "    n_layers=n_layers,\n",
    "    dropout=dropout,\n",
    "    conv_name='hgt',\n",
    "    prev_norm=False,\n",
    "    last_norm=False,\n",
    "    use_RTE=True\n",
    ").to(device)\n",
    "\n",
    "## Multi-label classifier\n",
    "class MultilabelClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "clf = MultilabelClassifier(hidden_dim, num_diseases).to(device)\n",
    "\n",
    "params = list(gnn.parameters()) + list(clf.parameters())\n",
    "\n",
    "optimizer = optim.Adam(params, lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # use cross-entropy if accuracy not enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3981e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test/val split\n",
    "\n",
    "all_patient_indices = np.array(list(graph.node_forward[\"patient\"].values())) #defined above also. incase of errors remove this line if needed\n",
    "np.random.shuffle(all_patient_indices)\n",
    "\n",
    "N = len(all_patient_indices)\n",
    "n_train = int(0.7 * N)\n",
    "n_val   = int(0.15 * N)\n",
    "\n",
    "train_idx = all_patient_indices[:n_train]\n",
    "val_idx   = all_patient_indices[n_train:n_train+n_val]\n",
    "test_idx  = all_patient_indices[n_train+n_val:]\n",
    "\n",
    "print(\"#train =\", len(train_idx))\n",
    "print(\"#val   =\", len(val_idx))\n",
    "print(\"#test  =\", len(test_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a036c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_batch_embeddings(batch_pids, graph, time_range, sampled_depth=2, sampled_number=8):\n",
    "    \n",
    "    inp = {\n",
    "        \"patient\": [(int(pid),0) for pid in batch_pids]\n",
    "    }\n",
    "\n",
    "    feature, times, edge_list, indxs, texts = sample_subgraph(\n",
    "        graph,\n",
    "        time_range={max_rel_time: True},\n",
    "        sampled_depth=2,\n",
    "        sampled_number=8,\n",
    "        inp = inp,\n",
    "        feature_extractor=feature_medical\n",
    "    )\n",
    "\n",
    "    node_feature, node_type, edge_time, edge_index, edge_type, node_dict, edge_dict = to_torch(\n",
    "        feature,times,edge_list, graph\n",
    "    )\n",
    "\n",
    "    node_feature = node_feature.to(device)\n",
    "    node_type = node_feature.to(device)\n",
    "    edge_time = node_feature.to(device)\n",
    "    edge_index = node_feature.to(device)\n",
    "    edge_type = node_feature.to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "        all_embs = gnn(node_feature, node_type, edge_time, edge_index, edge_type)\n",
    "\n",
    "    patient_offset, patient_type_id =node_dict[\"patient\"]\n",
    "\n",
    "    local_patient_ids = indxs[\"patient\"]\n",
    "    pid_to_local = {int(pid): i for i, pid in enumerate(local_patient_ids)}\n",
    "\n",
    "\n",
    "    selected_global_indices = []\n",
    "    for pid in batch_pids:\n",
    "        if pid in pid_to_local:\n",
    "            local_id = pid_to_local[pid]\n",
    "            global_node_idx = patient_offset + local_id\n",
    "            selected_global_indices.append(global_node_idx)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    if len(selected_global_indices) == 0:\n",
    "\n",
    "        return None, None\n",
    "    \n",
    "    selected_global_indices = torch.LongTensor(selected_global_indices).to(device)\n",
    "    batch_embs = all_embs[selected_global_indices]\n",
    "\n",
    "    batch_labels = Y[batch_pids]\n",
    "    batch_labels = batch_labels.to(device)\n",
    "\n",
    "    return batch_embs, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5692b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time range define\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "time_range={max_rel_time: True}\n",
    "\n",
    "#Train/val loop\n",
    "\n",
    "def evaluate(split_idx, graph, time_range, batch_size=64):\n",
    "    gnn.eval()\n",
    "    clf.eval()\n",
    "    losses = []\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(split_idx), batch_size):\n",
    "            batch_pids = split_idx[i:i+batch_size]\n",
    "            batch_embs, batch_labels = get_patient_batch_embeddings(\n",
    "                batch_pids, graph, time_range\n",
    "            )\n",
    "\n",
    "            if batch_embs is None:\n",
    "                continue\n",
    "\n",
    "            logits = clf(batch_embs)\n",
    "            loss = criterion(logits, batch_labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            trues = batch_labels.cpu().numpy()\n",
    "\n",
    "            all_preds.append(torch.sigmoid(logits).cpu())\n",
    "            all_trues.append(batch_labels.cpu())\n",
    "    \n",
    "    if len(losses) == 0:\n",
    "        return None, None\n",
    "    \n",
    "\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_trues = np.vstack(all_trues)\n",
    "\n",
    "    f1 = f1_score(all_trues.flatten(), all_preds.flatten(), zero_division=0)\n",
    "\n",
    "    return float(np.mean(losses)), float(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full training loop\n",
    "\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "sampled_depth=2\n",
    "sampled_number=8\n",
    "\n",
    "train_idx_arr = np.array(train_idx)\n",
    "val_idx_arr = np.array(val_idx)\n",
    "test_idx_arr = np.array(test_idx)\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    gnn.train()\n",
    "    clf.train()\n",
    "\n",
    "    perm = np.random.permutation(len(train_idx_arr))\n",
    "    train_idx_arr_shuffled = train_idx_arr[perm]\n",
    "\n",
    "    epoch_losses = []\n",
    "\n",
    "    for i in range(0, len(train_idx_arr), batch_size):\n",
    "        batch_pids = train_idx_arr_shuffled[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_embs, batch_labels = get_patient_batch_embeddings(\n",
    "            batch_pids, graph, time_range,\n",
    "            sampled_depth=sampled_depth,\n",
    "            sampled_number=sampled_number\n",
    "        )\n",
    "\n",
    "        if batch_embs is None:\n",
    "            continue\n",
    "        \n",
    "        logits = clf(batch_embs)\n",
    "        loss = criterion(logits, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    train_loss = np.mean(epoch_losses) if epoch_losses else None\n",
    "    val_loss, val_f1 = evaluate(val_idx_arr, graph, time_range, batch_size)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val F1 = {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c360a9b",
   "metadata": {},
   "source": [
    "### Testing and Testing Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6876d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_f1 = evaluate(test_idx_arr, graph, time_range, batch_size=64)\n",
    "print(f\"Test Loss = {test_loss:.4f}, Test F1 = {test_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhgt38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
